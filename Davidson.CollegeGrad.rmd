---
title: 'HarvardX: Ph125.9x Data Science Capstone College Graduation Rates Prediction
  Project'
author: "Chris Davidson"
date: "June 1, 2020"
output: pdf_document
---

# Introduction
In the field of Data Sciences and software, like R, provide data scientists the ability to conduct complex analyses of large datasets through machine learning to make predictions or classifications of an outcome. For the second component of the Harvardx Ph125.9x Data Science: Capstone Project, I created a large dataset from data in the Integrated Postsecondary Education Data System (IPEDS) from the US Department of Education's National Center for Education Statistics (NCES). 

## IPEDS Data 
The Department of Education collects data annually through a series of interrelated surveys that all institutions--college, university, technical, and vocational--that participate in federal Title IV financial aid programs established by the Higher Education Act of 1965. Annually, more than 7,500 institutions ranging from research universities, state colleges, private religious and liberal arts institutions, for-profit schools, community and technical colleges, and non-degree-granting institutions complete the surveys for IPEDS. 

Data collected from institutions include information in eight areas: 

* Institutional Characteristics;
* Institutional Prices;
* Admissions;
* Enrollment;
* Student Financial Aid;
* Degrees and Certificates Conferred; 
* Student Persistence and Success; and,
* Academic Libraries, Institutional, and Human Fiscal Resources.

## Purpose Statement 
As one of the definitive sources for information about postsecondary education in the US, IPEDS is used by Congress, federal and state government agencies, education leaders and researchers, private businesses, media, students, and parents for a variety of purposes. The purpose of this project was to develop and train a series of machine learning algorithms to predict college graduation rates reported in IPEDS and to maximize the accuracy of the algorithm. The Root Mean Square Error (RMSE) served as the value to evaluate the accuracy of each model. The RMSE is a standard way to measure the error between predicted and true values in a model. A smaller RMSE is interpreted as the model being more accurate than a larger RMSE. 

This report provides a description of the methods used to download and clean the data, dataset descriptive statistics, the methods to conduct an initial exploratory data analysis of the training subset of data before creating a series of machine learning algorithms. The report will then provide the results and offer a discussion of the analysis before providing concluding remarks. 

# Methods & Analysis

## College Graduation Dataset from IPEDS 
The data for this project came from a sample of data from IPEDS. The code to build the college dataset was written to merge eight separate data files to create the College Graduation Dataset that included 10-years of data to account for any anomalies in the data. The ninth file provides the definitions of the variables in the dataset. Once the files were merged, any cases that had at least one null value for any variable were removed from the dataset. After removing cases with null values, eighty percent of the dataset was split into the training dataset used for tuning and 20% split into a test dataset. The code also removed unneeded files from the working directory and environment. Table 1 describes the variables in the dataset. Table 2 provides the first six rows in the dataset.  

```{r Create Dataset, echo=FALSE, message=FALSE, warning=FALSE}
# Check and Install Required Packages
if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(broom)) install.packages("broom", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(data.table)) install.packages("data.table", repos = "http://cran.us.r-project.org")
if(!require(ggplot2)) install.packages("ggplot2", repos = "http://cran.us.r-project.org")
if(!require(knitr)) install.packages("knitr", repos = "http://cran.us.r-project.org")
if(!require(kableExtra)) install.packages("kableExtra", repos = "http://cran.us.r-project.org")
if(!require(rpart)) install.packages("rpart", repos = "http://cran.us.r-project.org")
if(!require(rattle)) install.packages("rattle", repos = "http://cran.us.r-project.org")
if(!require(randomForest)) install.packages("randomForest", repos = "http://cran.us.r-project.org")
if(!require(rpart.plot)) install.packages("rpart.plot", repos = "http://cran.us.r-project.org")

#####################################################
## Import IPEDS CSV Files from Github & Clean Data ##
sectors <- read.csv("https://raw.githubusercontent.com/drchrisd/gradrates/master/sectors.csv")
sectorlabels <- read.csv("https://raw.githubusercontent.com/drchrisd/gradrates/master/sectorlabels.csv")
fte <- read.csv("https://raw.githubusercontent.com/drchrisd/gradrates/master/fte.csv")
pell <- read.csv("https://raw.githubusercontent.com/drchrisd/gradrates/master/pell.csv")
f.s.ratio <- read.csv("https://raw.githubusercontent.com/drchrisd/gradrates/master/s.f.ratio.csv")
admit <- read.csv("https://raw.githubusercontent.com/drchrisd/gradrates/master/percent.admit.csv")
retention <- read.csv("https://raw.githubusercontent.com/drchrisd/gradrates/master/retention.csv")
gradrates <- read.csv("https://raw.githubusercontent.com/drchrisd/gradrates/master/grad.csv") 
variables <- read.csv("https://raw.githubusercontent.com/drchrisd/gradrates/master/Variables.csv")

###################################################
## Clean Data and Combine Files into the Dataset ##

# Clean Graduation Rates
names(gradrates) <- c("UnitID", "InstName", 2018:2009) #rename columns 
grad <- gradrates %>% select(UnitID, "2018") %>% mutate(Year = 2018)   #create subset of rates
names(grad) <- c("UnitID", "GradRate", "Year")   #rename columns 

#Bind rows into a tidy format 
grad <- bind_rows(grad, data.frame("UnitID" = gradrates$UnitID, "Year" = 2017, "GradRate" = gradrates$'2017')) %>%
  bind_rows(grad, data.frame("UnitID" = gradrates$UnitID, "Year" = 2016, "GradRate" = gradrates$'2016')) %>%
  bind_rows(grad, data.frame("UnitID" = gradrates$UnitID, "Year" = 2015, "GradRate" = gradrates$'2015')) %>%
  bind_rows(grad, data.frame("UnitID" = gradrates$UnitID, "Year" = 2014, "GradRate" = gradrates$'2014')) %>%
  bind_rows(grad, data.frame("UnitID" = gradrates$UnitID, "Year" = 2013, "GradRate" = gradrates$'2013')) %>%
  bind_rows(grad, data.frame("UnitID" = gradrates$UnitID, "Year" = 2012, "GradRate" = gradrates$'2012')) %>%
  bind_rows(grad, data.frame("UnitID" = gradrates$UnitID, "Year" = 2011, "GradRate" = gradrates$'2011')) %>%
  bind_rows(grad, data.frame("UnitID" = gradrates$UnitID, "Year" = 2010, "GradRate" = gradrates$'2010')) %>%
  bind_rows(grad, data.frame("UnitID" = gradrates$UnitID, "Year" = 2009, "GradRate" = gradrates$'2009'))

# Remove objects not needed
rm(gradrates)

# Clean Student:Faculty Ratio
names(f.s.ratio) <- c("UnitID", "InstName", 2018:2009) #rename columns 
ratio <- f.s.ratio %>% select(UnitID, "2018") %>% mutate(Year = 2018)   #create subset of ratios
names(ratio) <- c("UnitID", "SF.Ratio", "Year")   #rename columns 

#Bind rows into a tidy format 
ratio <- bind_rows(ratio, data.frame("UnitID" = f.s.ratio$UnitID, "Year" = 2017, "SF.Ratio" = f.s.ratio$'2017')) %>%
  bind_rows(ratio, data.frame("UnitID" = f.s.ratio$UnitID, "Year" = 2016, "SF.Ratio" = f.s.ratio$'2016')) %>%
  bind_rows(ratio, data.frame("UnitID" = f.s.ratio$UnitID, "Year" = 2015, "SF.Ratio" = f.s.ratio$'2015')) %>%
  bind_rows(ratio, data.frame("UnitID" = f.s.ratio$UnitID, "Year" = 2014, "SF.Ratio" = f.s.ratio$'2014')) %>%
  bind_rows(ratio, data.frame("UnitID" = f.s.ratio$UnitID, "Year" = 2013, "SF.Ratio" = f.s.ratio$'2013')) %>%
  bind_rows(ratio, data.frame("UnitID" = f.s.ratio$UnitID, "Year" = 2012, "SF.Ratio" = f.s.ratio$'2012')) %>%
  bind_rows(ratio, data.frame("UnitID" = f.s.ratio$UnitID, "Year" = 2011, "SF.Ratio" = f.s.ratio$'2011')) %>%
  bind_rows(ratio, data.frame("UnitID" = f.s.ratio$UnitID, "Year" = 2010, "SF.Ratio" = f.s.ratio$'2010')) %>%
  bind_rows(ratio, data.frame("UnitID" = f.s.ratio$UnitID, "Year" = 2009, "SF.Ratio" = f.s.ratio$'2009'))

# Remove objects not needed
rm(f.s.ratio)

# Clean FTE
names(fte) <- c("UnitID", "InstName", 2018:2009) #rename columns 
FTE <- fte %>% select(UnitID, "2018") %>% mutate(Year = 2018)   #create subset of ratios
names(FTE) <- c("UnitID", "FTE", "Year")   #rename columns 

#Bind rows into a tidy format 
FTE <- bind_rows(FTE, data.frame("UnitID" = fte$UnitID, "Year" = 2017, "FTE" = fte$'2017')) %>%
  bind_rows(FTE, data.frame("UnitID" = fte$UnitID, "Year" = 2016, "FTE" = fte$'2016')) %>%
  bind_rows(FTE, data.frame("UnitID" = fte$UnitID, "Year" = 2015, "FTE" = fte$'2015')) %>%
  bind_rows(FTE, data.frame("UnitID" = fte$UnitID, "Year" = 2014, "FTE" = fte$'2014')) %>%
  bind_rows(FTE, data.frame("UnitID" = fte$UnitID, "Year" = 2013, "FTE" = fte$'2013')) %>%
  bind_rows(FTE, data.frame("UnitID" = fte$UnitID, "Year" = 2012, "FTE" = fte$'2012')) %>%
  bind_rows(FTE, data.frame("UnitID" = fte$UnitID, "Year" = 2011, "FTE" = fte$'2011')) %>%
  bind_rows(FTE, data.frame("UnitID" = fte$UnitID, "Year" = 2010, "FTE" = fte$'2010')) %>%
  bind_rows(FTE, data.frame("UnitID" = fte$UnitID, "Year" = 2009, "FTE" = fte$'2009'))

# Remove objects not needed
rm(fte)

# Clean Pell
names(pell) <- c("UnitID", "InstName", 2018:2009) #rename columns 
PELL <- pell %>% select(UnitID, "2018") %>% mutate(Year = 2018)   #create subset of ratios
names(PELL) <- c("UnitID", "Pell", "Year")   #rename columns 

#Bind rows into a tidy format 
PELL <- bind_rows(PELL, data.frame("UnitID" = pell$UnitID, "Year" = 2017, "Pell" = pell$'2017')) %>%
  bind_rows(PELL, data.frame("UnitID" = pell$UnitID, "Year" = 2016, "Pell" = pell$'2016')) %>%
  bind_rows(PELL, data.frame("UnitID" = pell$UnitID, "Year" = 2015, "Pell" = pell$'2015')) %>%
  bind_rows(PELL, data.frame("UnitID" = pell$UnitID, "Year" = 2014, "Pell" = pell$'2014')) %>%
  bind_rows(PELL, data.frame("UnitID" = pell$UnitID, "Year" = 2013, "Pell" = pell$'2013')) %>%
  bind_rows(PELL, data.frame("UnitID" = pell$UnitID, "Year" = 2012, "Pell" = pell$'2012')) %>%
  bind_rows(PELL, data.frame("UnitID" = pell$UnitID, "Year" = 2011, "Pell" = pell$'2011')) %>%
  bind_rows(PELL, data.frame("UnitID" = pell$UnitID, "Year" = 2010, "Pell" = pell$'2010')) %>%
  bind_rows(PELL, data.frame("UnitID" = pell$UnitID, "Year" = 2009, "Pell" = pell$'2009'))

# Remove objects not needed
rm(pell)

# Clean Percent Admitted
names(admit) <- c("UnitID", "InstName", 2018:2009) #rename columns 
p.admit <- admit %>% select(UnitID, "2018") %>% mutate(Year = 2018)   #create subset of ratios
names(p.admit) <- c("UnitID", "PercAdmit", "Year")   #rename columns 

#Bind rows into a tidy format 
p.admit <- bind_rows(p.admit, data.frame("UnitID" = admit$UnitID, "Year" = 2017, "PercAdmit" = admit$'2017')) %>%
  bind_rows(p.admit, data.frame("UnitID" = admit$UnitID, "Year" = 2016, "PercAdmit" = admit$'2016')) %>%
  bind_rows(p.admit, data.frame("UnitID" = admit$UnitID, "Year" = 2015, "PercAdmit" = admit$'2015')) %>%
  bind_rows(p.admit, data.frame("UnitID" = admit$UnitID, "Year" = 2014, "PercAdmit" = admit$'2014')) %>%
  bind_rows(p.admit, data.frame("UnitID" = admit$UnitID, "Year" = 2013, "PercAdmit" = admit$'2013')) %>%
  bind_rows(p.admit, data.frame("UnitID" = admit$UnitID, "Year" = 2012, "PercAdmit" = admit$'2012')) %>%
  bind_rows(p.admit, data.frame("UnitID" = admit$UnitID, "Year" = 2011, "PercAdmit" = admit$'2011')) %>%
  bind_rows(p.admit, data.frame("UnitID" = admit$UnitID, "Year" = 2010, "PercAdmit" = admit$'2010')) %>%
  bind_rows(p.admit, data.frame("UnitID" = admit$UnitID, "Year" = 2009, "PercAdmit" = admit$'2009'))

# Remove objects not needed
rm(admit)

# Clean Retention Rate
names(retention) <- c("UnitID", "InstName", 2018:2009) #rename columns 
Retention <- retention %>% select(UnitID, "2018") %>% mutate(Year = 2018)   #create subset of ratios
names(Retention) <- c("UnitID", "Retention", "Year")   #rename columns 

#Bind rows into a tidy format 
Retention <- bind_rows(Retention, data.frame("UnitID" = retention$UnitID, "Year" = 2017, "Retention" = retention$'2017')) %>%
  bind_rows(Retention, data.frame("UnitID" = retention$UnitID, "Year" = 2016, "Retention" = retention$'2016')) %>%
  bind_rows(Retention, data.frame("UnitID" = retention$UnitID, "Year" = 2015, "Retention" = retention$'2015')) %>%
  bind_rows(Retention, data.frame("UnitID" = retention$UnitID, "Year" = 2014, "Retention" = retention$'2014')) %>%
  bind_rows(Retention, data.frame("UnitID" = retention$UnitID, "Year" = 2013, "Retention" = retention$'2013')) %>%
  bind_rows(Retention, data.frame("UnitID" = retention$UnitID, "Year" = 2012, "Retention" = retention$'2012')) %>%
  bind_rows(Retention, data.frame("UnitID" = retention$UnitID, "Year" = 2011, "Retention" = retention$'2011')) %>%
  bind_rows(Retention, data.frame("UnitID" = retention$UnitID, "Year" = 2010, "Retention" = retention$'2010')) %>%
  bind_rows(Retention, data.frame("UnitID" = retention$UnitID, "Year" = 2009, "Retention" = retention$'2009'))

# Remove objects not needed
rm(retention)

#Create College dataset for modeling using left joins
College <- grad %>% 
  left_join(sectors, by = 'UnitID') %>%   
  left_join(sectorlabels, by = 'Sector.of.institution') %>% 
  select(-Sector.of.institution)
College <- College %>% cbind("FTE" = FTE$FTE, 
                             "PercAdmit" = p.admit$PercAdmit, 
                             "PELL" = PELL$Pell, 
                             "SF.Ratio" = ratio$SF.Ratio, 
                             "Retention" = Retention$Retention)

#Remove objects
rm(FTE, grad, p.admit, PELL, ratio, Retention, sectorlabels, sectors)

#Rename column
names(College)[5] <- "Sector" 

#Reorder columns
College <- College[,c(1,4,5,3,2,6:10)]

#Remove cases with at least one null value
College <- College[complete.cases(College),]

#Test set will be 20% College dataset
set.seed(1, sample.kind="Rounding")
test_index <- createDataPartition(y = College$GradRate, times = 1, p = 0.2, list = FALSE)
train <- College[-test_index,]
test <- College[test_index,]

#Remove unneeded objects
rm(test_index)

#Create data.frame with variables and definitions
kable(variables, booktabs=T, caption = "College Graduation Dataset Variables and Definitions") %>%
  kable_styling(latex_options = c("striped", "hold_position"), full_width = F) %>%
  column_spec(2, width = "30em")

```

```{r College Dataset First Six Rows, echo=FALSE, message=FALSE, warning=FALSE, tidy=TRUE}
## First 6 Rows of College Dataset ##
head(College) %>% 
  knitr::kable("latex", booktabs=TRUE, caption = "First Six Rows of the College Graduation Dataset") %>%
  kable_styling(latex_options = c("striped", "scale_down", "hold_position"))

```

\newpage

The final College Graduation Dataset consisted of 29,103 graduation rates for 1,803 individual institutions across three sector types. An overwhelming majority of colleges are classified as Private not-for-profit, four-year or above; followed by public, four-year colleges; and Private for-private, four-year. Years in the dataset ranged from 2009 to 2018. Graduation Rate in the dataset ranged from 0% to 100% and a mean of 53%. Full-time equivalent enrollment, or FTE, ranged from 6 to 77,707 with a mean of 5,756 students. The low mean for FTEs given the range indicates that many of the institutions in the dataset have much smaller enrollments than larger enrollments. The Percent Admitted, used in this study as a proxy for selectivity in admissions, ranges from 0% to 100% with a mean of 66.62%. The Percent Admitted mean indicates that institutions in the dataset are less selective with a mean above 50%. The percentage of PELL Grant Recipients, a proxy for socioeconomic status, ranged from 0% to 100% with a mean of 40.46%. Given the mean percentage of PELL Grant Recipients, indicates that the first-time full-time degree-seeking students tend to not come from lower socioeconomic statuses. The Student-to-Faculty Ratios range from one student to 107 students for every one faculty member with a mean 14.14. The Retention Rates range from 0 to 100% with a mean of 75.28%, which are relatively high. Table 3 provides the full summary of all of the variables in the College Graduation Dataset. 

```{r College Dataset Descriptives, echo=FALSE, message=FALSE, warning=FALSE, tidy=TRUE}
## Descriptives of College Dataset ##
summary(College) %>% 
  knitr::kable("latex", booktabs=TRUE, caption = "Descriptives of the College Graduation Dataset") %>%
  kable_styling(latex_options = c("striped", "scale_down", "hold_position"))

```

## Exploratory Analysis of the Training Dataset 
The first step in the analysis was to examine the training dataset to understand its components before using it to create the machine learning algorithms to predict graduation rates. Table 4 summarizes the training set and as we already know, there are no null values in the data because we removed those in the initial cleaning phase. 

```{r, Descriptives of Training Dataset, echo=FALSE, message=FALSE, warning=FALSE, tidy=TRUE}
#Descriptives of Training Dataset 
kable(summary(train), booktabs=T, caption = "Descriptives of Training Dataset") %>%
  kable_styling(full_width = F, latex_options = c("striped", "scale_down", "hold_position")) 

```

\newpage

### Distribution of Gradaution Rates
Graduation rates in the training dataset ranged from 0% to 100%. The majority of graduation rates were above approximately 40%. Even though some institutions had a 0% graduation rate, the distribution of graduation rates shows that the data is slightly skewed towards higher graduation rates. 

```{r Dist Grad Rate, echo=FALSE, message=FALSE, warning=FALSE, tidy=TRUE}
#Distribution of Graduation Rates 
train %>% ggplot(aes(GradRate)) +
  geom_histogram(fill = "dark blue", color = "white", bins = 10) +
  ggtitle("Distribution of Graduation Rates")

```

\newpage

### Graduation Rates by Institution Sector
Examining the distribution of graduation rates by institution sector shows the Private not-for-profit institutions had the highest graduation rates of the three sectors, which may partly be because of the number of institutions. Public institutions had the second-highest graduation rates that are centered around in the histogram. Institutions from these two sectors had significantly higher graduation rates than the Private for-profit institutions showing a bias against Private for-profit institutions in the data.   

```{r Dist Grad Rate Sector, echo=FALSE, message=FALSE, warning=FALSE, tidy=TRUE}
#Distribution of Graduation Rates by Institution Sector
train %>% ggplot(aes(GradRate, fill = Sector)) +
  geom_histogram(bins = 10, alpha = .5, aes(y = ..count..),
                 position = 'identity', color = 'white') +
  scale_fill_manual(values = c("darkred", "darkblue", "orchid3")) +
  ggtitle("Disribution of Graduation Rates by Sector")

```

\newpage

### Graduation Rates by Year
As previously mentioned, 10-years' worth of data were used to take into consideration any anomalies or fluctuations in a single year within the data. Examining the average graduation rate by year for each sector, the Private for-profit sector shows the most fluctuations in average graduation rates over the decade. Overall, Public institutions saw a steady increase after a slight decrease in 2010. Private not-for-profit institutions saw a steep decrease from 2012 to 2013 and a steady increase afterward.     

```{r Dist Grad Rate by Year, echo=FALSE, message=FALSE, warning=FALSE, tidy=TRUE}
#Graduation Rates by Year
train %>% group_by(Sector, Year) %>%
  summarise(GradRate1 = mean(GradRate, na.rm = TRUE)) %>%
  ggplot(aes(Year, GradRate1, color = Sector)) +
  geom_point() +
  geom_line() +
  ylab("Graduation Rate") +
  scale_color_manual(values = c("darkred", "darkblue", "orchid3")) +
  ggtitle("Average Graduation Rate by Year")

```

\newpage

### Distribution of FTEs 
The distribution of the FTE enrollment shows that FTEs are skewed towards smaller enrollments with fewer than 15,000 total FTEs. 

```{r FTEs, echo=FALSE, message=FALSE, warning=FALSE, tidy=TRUE}
#Distribution of FTEs
train %>% ggplot(aes(FTE)) +
  geom_histogram(fill = "dark blue", color = "white", bins = 15) +
  scale_x_continuous(breaks = c(seq(0, 60000, 15000))) +
  ggtitle("Distribution of FTEs")

```

\newpage

### Distribution of Percent Admitted
The distribution of the Percent of Students Admitted, representing the selectivity of institutions, shows that an overwhelming majority of institutions are less selective with the percent admitted well above 50%. 

```{r Percent Admitted, echo=FALSE, message=FALSE, warning=FALSE, tidy=TRUE}
#Distribution of Percent Admitted
train %>% ggplot(aes(PercAdmit)) +
  geom_histogram(fill = "darkblue", color = "white", bins = 10) +
  ggtitle("Distribution of Percent of Students Admitted")

```

\newpage

### Distribution of Percent of Pell Recipients 
The distribution of Pell Grant Recipients shows that an overwhelming majority of institutions do not have a large population of Pell Grant recipients indicating that there are fewer students from lower socioeconomic statuses.  

```{r Percent Pell, echo=FALSE, message=FALSE, warning=FALSE, tidy=TRUE}
#Distribution of Percent of Pell Recipients
train %>% ggplot(aes(PELL)) +
  geom_histogram(fill = "darkblue", color = "white", bins = 10) +
  ggtitle("Distribution of Percent of PELL Recipients")

```

\newpage

### Distribution of the Student to Faculty Ratio
The distribution of student to faculty ration shows that most institutions have a student to faculty ratio of 20 or fewer students for every one faculty member. 

```{r Stu to Fac Ratio, echo=FALSE, message=FALSE, warning=FALSE, tidy=TRUE}
#Distribution of Student to Faculty Ratio
train %>% ggplot(aes(SF.Ratio)) +
  geom_histogram(fill = "darkblue", color = "white", bins = 15) +
  scale_x_continuous(breaks = c(seq(0, 40, 10))) +
  ggtitle("Distribution of Student to Faculty Ratio")

```

\newpage

### Distribution of Retention Rate 
The distribution rate shows that a majority of institutions have a 6-year graduation rate of more than 60%, which is a good indicator that many students will be retained and persist to graduation. 

```{r Retention Rate, echo=FALSE, message=FALSE, warning=FALSE, tidy=TRUE}
#Distribution of Retention Rate
train %>% ggplot(aes(Retention)) +
  geom_histogram(fill = "darkblue", color = "white", bins = 10) +
  ggtitle("Distribution of Retention Rate")

```

## Modeling 
For the learning algorithms, I used the RMSE to determine the accuracy of the model. As previously stated, the RMSE, or Root Mean Square Error, measures the error between the predicted and observed values. This means that the smaller the RMSE, the more accurate the model. Mathematically, the formula for the RMSE is written as:
$$ RMSE = \sqrt{\frac{1}{N}\displaystyle\sum_{u,i} (\hat{y}_{u,i}-y_{u,i})^{2}} $$
```{r RMSE, echo=FALSE, message=FALSE, warning=FALSE, tidy=TRUE}
#Set Seed 
set.seed(1, sample.kind="Rounding")


#Create Function to Calculate RMSE
RMSE <- function(predicted_ratings, true_ratings,...){
  sqrt(mean((predicted_ratings - true_ratings)^2,...))
}
  
```

For this project, I will create five models to evaluate the predictive power of each model. The five following models: (a) Best Guess, (b) Multiple Linear Regression, (c) Regression Tree, (d) Pruned Regression Tree, and (e) Random Forest models, are defined in subsequent sections. 

### Model I: Best Guess Model
The first model is a simple best guess for the graduation rate. This model ignores all predictors and all errors are explained as random variation in the model. We know that the mean of the graduation rates is 53.20553, which is close enough to a 50/50 guess. We know that the simplest best guess model is just that, a guess, meaning we can do better and improve the accuracy of the predictions. 

### Model II: Multiple Linear Regression 
Multiple linear regression can be used as a form of machine learning that controls for the various predictors in the model. While simple multiple linear regression can be useful, at times it can be too rigid for predictive power depending on the data. In this case, I will use it as the general baseline along with the Best Guess model as the baseline for more advanced models. 

### Model III: Regression Tree
Regression trees are a basic yes or no flow chart. Since our outcome variable, graduation rates, is continuous and we have more than a few predictors, a regression tree allows us to predict the outcome by partitioning the predictors. This partitioning occurs and creates nodes, or trees with predictions at the ends. Within the partitioning process, the complexity parameter and the minimum number of observations required before moving on to the next partition.   

### Model IV: Pruned Regression Tree
Once I create my initial regression tree, I will use the pruning process to apply a higher complexity parameter. This simply means that I will be snipping off partitions that do not meet the complexity parameter criterion.

### Model V: Random Forests 
The last model I will create will be the random forests model. The goal is to improve the predictive power and reducing any instability by introducing randomness through bootstrapping and by averaging multiple decision trees. Within this process bootstrapping. Since the con to this method is the loss of interpretability, I will examine variable importance to determine which variable(s) are most important in the model. 

# Results 
My purpose for this project was to develop and train a series of machine learning algorithms to predict college graduation rates reported in IPEDS and to maximize the accuracy, measured by the RMSE. 

## Model I - Best Guess
Without using any other predictors, our best guess for a graduation rate would be 53.20281%. Using the formula and respective function I calculated the RMSE as 19.93759. This RMSE will be used as the baseline to compare all other models moving forward because the model should become more accurate as predictors and algorithms are tuned and tested.   

```{r Model1, echo=FALSE, message=FALSE, warning=FALSE, tidy=TRUE}
#MODEL 1: BEST GUESS MODEL 
mu <- mean(train$GradRate)

# Test Model 1
RMSE1 <- RMSE(test$GradRate, mu)

#Create Data Frame for RMSE Results of Models 
Models <- data_frame(Method="Model I: Best Guess - Baseline", RMSE = RMSE1)
Models %>% knitr::kable(booktabs=T, caption = "Results of RMSEs") %>%
  kable_styling(full_width = F, latex_options = "hold_position")

```

## Model II - Multiple Linear Regression
Through the exploratory data analysis, we found that the graduation rates and other variables did not have a normal distribution, which is not surprising given the type of data being used. Examining the linear model, all of the variables were statistically significant with a p-value < .05, except for the Private not-for-profit sector, 4-year and above sector. To accept the linear model, I would need to be examined further because the model only explains about 59.3% in the variance of predicted values, which means the model is not a strong predictor even though the RMSE improved greatly to 12.847343.  

```{r Model2, echo=FALSE, message=FALSE, warning=FALSE, tidy=TRUE}
#MODEL 2: MULTIPLE LINEAR REGRESSION 
#Calculate Linear Regression Model
LinearFit <- lm(GradRate ~ Sector + Year + FTE + PercAdmit + PELL + 
                  SF.Ratio + Retention, data = train)

#Review Linear Model
tidy(LinearFit) %>%  knitr::kable(booktabs=T, caption = "Multiple Linear Regression") %>%
  kable_styling(latex_options = "hold_position", full_width = F) 

#Use Model to make Predictions 
LinearPredict <- predict(LinearFit, test)

#Evaluate the accuracy by RMSE 
RMSE2 <- RMSE(LinearPredict, test$GradRate)

#Add RMSE Restult to Data Frame
Models <- bind_rows(Models,
                    data_frame(Method="Model II: Multiple Linear Regression", RMSE = RMSE2))

Models %>% knitr::kable(booktabs=T, caption = "Results of RMSEs") %>%
  kable_styling(full_width = F, latex_options = "hold_position")

```

## Model III - Regression Tree
Moving beyond simple linear regression, I used Regression Trees as the next way to create a predictive model. In this regression tree, we see a total of nine nodes where the tree branches. For institutions that have a retention rate below 79%, retention rates below 68%, and have 77% or more first-time full-time students with PELL Grants, the average graduation rate is 26%. For the institutions that have below a 77% PELL Grant rate, the average graduation rate is 38%. For colleges that have a retention rate above 68% but under 79%, and have a PELL Grant rate of 64% or above the average graduation rate is 35%. For colleges that have a retention rate above 68% but under 79%, and have a PELL Grant rate of below 64% the average graduation rate is 49%. 

For Retention Rates above 79% with a PELL Grant rate of 25% or above and an FTE below 650, the average graduation rate is 40%. For Retention Rates above 79% with a PELL Grant rate of 25% or above and an FTE above 650 and the PELL Grant rate is equal to or above 42%, the average graduation rate is 54%. For Retention Rates above 79% with a PELL Grant rate of 25% or above and an FTE above 650 and the PELL Grant rate is below 42%, the average graduation rate is 64%. 

For Retention Rates above 79% with a PELL Grant rate of less than 25%, the Percent Admitted above or equal to 53% and an FTE below 128, the average graduation rate is 26%. For Retention Rates above 79% with a PELL Grant rate of less than 25%, the Percent Admitted above or equal to 53% and an FTE above 128, the average graduation rate is 71%. For Retention Rates above 79% with a PELL Grant rate of less than 25%, the Percent Admitted below 53%, the average graduation rate is 85%. The Regression Tree model improved slightly from the multiple linear regression model to 12.74843. 

```{r Model3, echo=FALSE, message=FALSE, warning=FALSE, tidy=TRUE}
#MODEL 3: Regression Tree
#Apply rpart to obtain regression tree 
RTreeFit <- rpart(GradRate ~ Sector + Year + FTE + PercAdmit + PELL + 
     SF.Ratio + Retention, data = train)

#View regression tree
fancyRpartPlot(RTreeFit, palettes = "Blues")

#Use model to make prediction
RTreePredict <- predict(RTreeFit, test)

##Evaluate the accuracy by RMSE 
RMSE3 <- RMSE(RTreePredict, test$GradRate)

#Add RMSE Result to Data Frame
Models <- bind_rows(Models,
                    data_frame(Method="Model III: Regression Tree", RMSE = RMSE3))
Models %>% knitr::kable(booktabs=T, caption = "Results of RMSEs") %>%
  kable_styling(full_width = F, latex_options = "hold_position")

```

## Model IV - Pruned Regression Tree
Taking the previous model, and by using cross-validation, I found the optimal complexity parameter by examining the smallest standard error of the factors and at which split it occurred. By pruning these lower-level decision nodes, I can introduce a little bit of bias in the model that helps stabilize predictions for the future  and in turn will be able to better generalize to new data.  The lowest complexity parameter occurred at the ninth split; however, after building the Pruned Regression Tree, there is no improvement in the RMSE.  

```{r Model4, echo=FALSE, message=FALSE, warning=FALSE, tidy=TRUE}
#MODEL 4: Pruned Regression Tree
#Review cross validation results to find optimal CP (xerror column)
#9 Splits, CP = .01
tidy(printcp(RTreeFit))

#Prune the regression tree
RTreePruned <- prune(RTreeFit, cp=.01)

#View pruned regression tree
fancyRpartPlot(RTreePruned, palettes = "Blues")

#Use pruned tree model to make prediction
PrunedRT_Predict <- predict(RTreePruned, test)

#Evalute the accuracy by RMSE
RMSE4 <- RMSE(PrunedRT_Predict, test$GradRate)

#Add RMSE Result to Data Frame
Models <- bind_rows(Models,
                    data_frame(Method="Model IV: Pruned Regresstion Tree", RMSE = RMSE4))

```

## Model V - Random Forest
I used the Random Forest algorithm to predict college graduation rates as the final model reaches the minimum error estimate occurred is after 438 trees, where the line on the plot levels out. Since the limitation of Random Forests is interpretability, I examined the importance of variables by looking at how many times it appears in the trees. The Retention Rate variable appears to be the variable used most and is driving the model, which is logical because institutions with higher retention rates would have higher graduation rates. After using the model to predict graduation rates, the RMSE dropped significantly to 7.391587 from all other models. 

```{r Model5, echo=FALSE, message=FALSE, warning=FALSE, tidy=TRUE}
# MODEL 5: RANDOM FORESTS
#Create a random forest 
RForest <- randomForest(GradRate ~ Sector + Year + FTE + 
                          PercAdmit + PELL + SF.Ratio + Retention, data = train)

#Plot to see errors by number of trees with line at minimum error
plot(RForest) +
abline(v = which.min(RForest$mse), col="blue")

#Number of trees to reach minimum error estimate 
which.min(RForest$mse) %>%  knitr::kable(booktabs=T, caption = "Minimum Error Estimate") %>%
  kable_styling(full_width = F, latex_options = "hold_position")

#Use the importance() function to determine the importance of each variable 
RFImportance <- varImp(RForest, type=2, scale=TRUE)
names(RFImportance) <- c("IncNodePurity")    #rename column
RFImportance %>% knitr::kable(booktabs=T, caption = "Variable Importance") %>%
  kable_styling(full_width = F, latex_options = "hold_position")

#Use the model to make prediction 
RForestPredict <- predict(RForest, test)

#Evalute the accuracy by RMSE
RMSE5 <- RMSE(RForestPredict, test$GradRate)

#Add RMSE Result to Data Frame
Models <- bind_rows(Models,
                    data_frame(Method="Model V: Random Forest", RMSE = RMSE5))

#Print RMSE 
Models %>% knitr::kable(booktabs=T, caption = "Results of RMSEs") %>%
  kable_styling(full_width = F, latex_options = "hold_position")

```

# Limitations
As with any project, there are limitations. For this project, the limitations include the dataset itself and within some of the models. Within the dataset itself, I did not choose all possible variables from IPEDS that could have been included because of the sheer amount of data collected by the Department of Education. Additionally, some of these variables, including those that I ended up choosing could be correlated with one another and end up skewing some of the results. This is evident in the linear regression model and the percentage of variance, or lack thereof, that is explained. 

# Conclusion 
Using data from IPEDS at the Department of Education, I used a series of machine learning algorithms to predict graduation rates at Public, Private not-for-profit, and Private for-private four-year institutions.  After using Multiple Linear Regression, Regression Trees, and Random Forests algorithms, the best model produced came from the Random Forests mode with the smallest RMSE. Moving forward, future research may use these and other algorithms with additional data, including some of the institutions excluded because of missing values. Additionally, other variables could be looked at from IPEDS as well as looking to avoid issues of collinearity and covariance, which affects the final models. With the inclusion of other data and building upon the work of this project, insights gained could provide information for data-informed decision making at institutions of higher education to determine where to invest resources to increase an institution's graduation rate.   
